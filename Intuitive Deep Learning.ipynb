{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuitive Deep Learning\n",
    "\n",
    "In this notebook will be create my very first Convolutional neural network to predict what is contained within the image (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck). We will fo through the following in this notebook:\n",
    "* Exploring and Processing the Data\n",
    "* Building and Training our Convolutional Neural Network\n",
    "* Testing out with your own images\n",
    "\n",
    "Note that the results you get might differ slightly from the blogspot as there is a degree of randomness in the way we split our dataset as well as the initialization of our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring and Processing the Data\n",
    "\n",
    "We will first have to download our dataset, CIFAR-10. The details of the dataset are as follows:\n",
    "* Images to be recognized: Tiny images of 32 * 32 pixels\n",
    "* Labels: 10 possible labels (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck)\n",
    "* Dataset size: 60000 images, split into 50000 for training and 10000 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now take a look at an individual image. If we print out the first image of our training dataset (x_train[0]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 59  62  63]\n",
      "  [ 43  46  45]\n",
      "  [ 50  48  43]\n",
      "  ...\n",
      "  [158 132 108]\n",
      "  [152 125 102]\n",
      "  [148 124 103]]\n",
      "\n",
      " [[ 16  20  20]\n",
      "  [  0   0   0]\n",
      "  [ 18   8   0]\n",
      "  ...\n",
      "  [123  88  55]\n",
      "  [119  83  50]\n",
      "  [122  87  57]]\n",
      "\n",
      " [[ 25  24  21]\n",
      "  [ 16   7   0]\n",
      "  [ 49  27   8]\n",
      "  ...\n",
      "  [118  84  50]\n",
      "  [120  84  50]\n",
      "  [109  73  42]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[208 170  96]\n",
      "  [201 153  34]\n",
      "  [198 161  26]\n",
      "  ...\n",
      "  [160 133  70]\n",
      "  [ 56  31   7]\n",
      "  [ 53  34  20]]\n",
      "\n",
      " [[180 139  96]\n",
      "  [173 123  42]\n",
      "  [186 144  30]\n",
      "  ...\n",
      "  [184 148  94]\n",
      "  [ 97  62  34]\n",
      "  [ 83  53  34]]\n",
      "\n",
      " [[177 144 116]\n",
      "  [168 129  94]\n",
      "  [179 142  87]\n",
      "  ...\n",
      "  [216 184 140]\n",
      "  [151 118  84]\n",
      "  [123  92  72]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see the image as an image rather than a series of pixels value numbers, we will use a function from matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label is: [6]\n"
     ]
    }
   ],
   "source": [
    "print('The label is:', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore one more image, the second image (with index 1 instead of 0) in our training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAfq0lEQVR4nO2da5BdV5Xf/+u++v1utdSSWmpJloRs2ZaMUGzsAIlnsCGkDDWBgg8Tf6BG8wEqoTL54GKqAvlGUoEpPiRUmeAaMyE8KsDgMkwGxxgM4xfySw/L1vvd3ZJaavXrvu/Kh76uks3+726r1bc1c/6/qq6+vVfvc/bd56xz7t3/s9Yyd4cQ4p8+qeUegBCiMcjZhUgIcnYhEoKcXYiEIGcXIiHI2YVICJnFdDazBwF8E0AawP9096/F/r+js8v7BlYGbaXCLO1XKRWC7e5G+2RzzdSWa+K2dDZHbalUeH+F/DTtUyrmqc2rVWoz8PeWSqd5v1T4+t3W3kH7NEXmw6sVasvn+TEDwpJuzWu0RyHP56oaGUdMPmamSoWPo1aLbY/3y2S4O2Uy/Jg5wudBTBWvkWHkZ/MoFkvBk+e6nd3M0gD+O4A/BnAWwO/N7Al3f4P16RtYib/8xv8I2s6++TLd18UTh4Lt1Sof/sp176O2dZu2UVvPqnXU1twS3t/hg8/RPqeO7qO28hS/SKQj762zp4vaMs2twfbd936I9rllC5+rwtXL1HbwwKvUVquVgu2lcvjCDQBvHNxPbZMTl6itWCpSW7kUdrLL4/xCNT3Lx1ip8n2tWNFLbT297dRW9anwvsq0Cwr58JXg18+8QPss5mP8bgBH3f24u5cA/ADAQ4vYnhBiCVmMs68BcOaav8/W24QQNyGLcfbQ94I/+GxhZnvMbK+Z7Z2avLqI3QkhFsNinP0sgKFr/l4L4Py7/8ndH3X3Xe6+q6OTf9cUQiwti3H23wPYbGYbzCwH4LMAnrgxwxJC3GiuezXe3Stm9kUAf4856e0xdz8Y61OtVjF5Jby629fNVzJ9RViu80wn7TO4biMfR40vc6ZqfJW2NhuWfwpXxmkfz/OV3TX9A9S2bugWahu6ZT21rV6zNtg+QCRPAMhmm6it0h1e3QeAobWreL9KeDW+UODy2sQVrk5cusRVgUxEZoWFV+N7+vh7bm7jY7w6eYXampq5O9WcS4fZTHgsk1cnaJ9SMbwa70yTwyJ1dnf/BYBfLGYbQojGoCfohEgIcnYhEoKcXYiEIGcXIiHI2YVICItajX/PuAPlsOxVKnI5bHY2LOMMb+FP507PzFBbLBijtz8SZJINXxs3b95C+3zw7l3UtmZlWCYDgK6uFdRWzvBoudbmsIyTiURQWSUS2TbD5bAiOZYA0NoSlux6urncuGnjrdR26NBb1Abj4ygWw1JqV2cP7RMJfMTVyTFqc4TPUyAeSXflSvhczc/yoBsWEReLANSdXYiEIGcXIiHI2YVICHJ2IRKCnF2IhNDQ1Xiv1VAhgRBW4SvMTbmWYPvVSzxVUd8qvtK97jYeZDIwtJrasmyZNpI/qFzhK/9vjvAAmtnjF/k2U3zV9639rwfbP7CNr3R/aPcHqC22ujsZyU9w+tQfRDsDAHLZSG7AHA9s6l/BlZfTZ47wbZI0XdN5rtZMTvLzKpPluQE7O3nQUCxfH0uvF8uT19QUPheND093diGSgpxdiIQgZxciIcjZhUgIcnYhEoKcXYiE0HDprTgbljzaW7gk09kbDgq5684dtM/Qxs3UNhUJ/Hjr+Blqm5wNyyfTEzxX2PgEl9dGRnk+s85IIAxSPEDiyR/+ONie/Qy/rn/4nvuoLZvlsuKqVVymhIflq4kr4eonAPDKq7x6TiaSJ6+tg0t2lWpYOixN82OWjtwCY1VfqlUuiY5f5nJeCmHJLlZOqrs7HLCVjpSZ0p1diIQgZxciIcjZhUgIcnYhEoKcXYiEIGcXIiEsSnozs5MApgBUAVTcnSdcA2ApQ1NTNmgrpztov3xLuJD9iUlepue1371EbZfHeV61c+d5jrFsOhxSlE3x6KQiKYMEAIUCtw2u4Ifmwugpausk0VBTE5O0z+ETJ/g4BvupLZvlYxwcCpeGWk3aAeD0KJc939rPbQODXKY8eZpIXmV+zGolbqtG8v8157g82JQJn/cAkC+Et9nZySXFDCkZZZH7943Q2f+FOxFVhRA3DfoYL0RCWKyzO4BfmtnLZrbnRgxICLE0LPZj/L3uft7MBgA8ZWZvuvuz1/5D/SKwBwC6e/ijhkKIpWVRd3Z3P1//fQHATwHsDvzPo+6+y913tbWHF9qEEEvPdTu7mbWZWcfbrwF8FMCBGzUwIcSNZTEf41cC+KnNZbjLAPjf7v5/Yx1SqQxaW1cGbRcmeCTa0TNh2eWNg/zakorIQtVIqan8FE9EmCYSW77IZa2JKW6bipRWOnn2ELW1tXCZcuumrWFDRAL8h9/+mtrWb9hAbVu28rJXfX3hqKymZn5cujq5dJWq8OSWM0V+z2IllPITPPquWuVJQptbuIQ2Pcm32RmJzGtqDkeqlUqxkmjhCMxajcuG1+3s7n4cwJ3X218I0VgkvQmREOTsQiQEObsQCUHOLkRCkLMLkRAamnAync6guzccRXX0zGHab+RkOCqrNcsTL16d4ckcpycvUJtFpIuJqbBUNpHnUk2GRPkBQP/KAWpr6QhLVwCwZpiLIENExjnx+vO0T9q4LFeu8iivi5d4Ms3bb98WbL9l80baZygSvdZ+905q2/fmaWorFsKJTIvZSNQbuExWcy4Rj46G69sBQK6Jy4pdPew84DJwPh+O+Kw5f1+6swuREOTsQiQEObsQCUHOLkRCkLMLkRAauhpfLM7g2LFwbrg3jx2l/c6PHAu2VyNBKx1dbdS2dfMwtW3ftp3aRi6GV0BPXeTjWLEqHPgDAOs38SCTjj6+Uj92he/PL4WVi9On+Ir1xUiJqm23UhP+eEt4xR0AZqbJajFf3IeXuCpw8AWuJmzeysuArVzTHWx/4aVng+0AMDrGg5fKZb4aX8jz8V+JlL1qaQ+PMbayPkPKqMUCYXRnFyIhyNmFSAhydiESgpxdiIQgZxciIcjZhUgIDZXeZqYn8cKzT4UHspLkTgOwadvtwfaWSJmebbdupratW9ZSW7UQDiQBAE+F5aQZ8II4mWw4EAMA0umw5AIA5QoPnJiZukxtXaWwNFSpOu1z+gIPGmpuP8f31dlDbRs3DQfbPXJ/yU+E86oBwJsvvkZtnufnwfYHHgy2334HD8jJ7+XS27GjJ6mttZVnT+7q7qO2ueppf8jkJD8uxWJ4rlzSmxBCzi5EQpCzC5EQ5OxCJAQ5uxAJQc4uREKYV3ozs8cAfALABXffXm/rBfBDAMMATgL4jLtznaBOuVTBhTNhmWrnnf+K9mtqCucm6+UqGQZX8zxilyOlf84c5bJWqRaWw1LGQ7nSGS6FVJ3n0EMlVr4qLAECgFfD+2vvCuf+A4DxaR5Fl8rx6MGaczlvrpp3qBPv0d7Mj9nw6iFqa07zcaQQzht4+3YecdjdzSXRJ/K/pLbREe4CawZWU1vVwjkMs5ESZpOTYXnwUDZcKg1Y2J39rwG8W6x8BMDT7r4ZwNP1v4UQNzHzOnu93vq7b3cPAXi8/vpxAJ+8weMSQtxgrvc7+0p3HwGA+m+eaUEIcVOw5I/LmtkeAHsAIJvlOdSFEEvL9d7Zx8xsEADqv2nVBXd/1N13ufuuTKahj+ILIa7hep39CQAP118/DOBnN2Y4QoilYiHS2/cBfARAv5mdBfAVAF8D8CMz+zyA0wA+vZCdpVIZtLb3Bm3ZiIozMRH+4NDUyyWS2QrXeAq8WhNaejqoralmZINcevPIDBfKPMqruYV3TEXKNdVS4X7tfVz6yTmXG9MtPLLNc1z7rFn4vVmVS3mpNH/P2bYctbW0c1ulGJZZx8+N0T59bbwM1UMff4Da9r5+ktqmI8koC8WLwfYiKfEEAN0d4XM/k+bHZF5nd/fPEdP98/UVQtw86Ak6IRKCnF2IhCBnFyIhyNmFSAhydiESQkOfcsnlmjC4LhxtZCl+3SkUwhE+Y5N8+LluHuVVrnCpxiJP+eWnwxFUZedjz2R44shKmttaO3kE2EDfBLX55bBcU4rUKLMaH39LSwu1pSJRhzUP769a5TJlKhtJ9pnmY5ye4VGMRhIwNkXOt8mLXJZraQ1LxwDwoXvuoLa3jp2itgNvjAbbpyd5NGKOJDKt1WIRgEKIRCBnFyIhyNmFSAhydiESgpxdiIQgZxciITRUenMD3MLySjkiDc1OhaWVpogsNDUZSRxZ4IkeZye5jJMlQW8dbVxCW9HDpZrOXh4BtqKbv7dqpova8k3heby8nke9Fasj1IZIZF61Eom+IxGC1RSPRrSI9Nbdy6PvatXIGMl51dXF5zdnXL6amIrInuWwNAsAO7atorbujvD58+STPLnlxbFw4tZKxI90ZxciIcjZhUgIcnYhEoKcXYiEIGcXIiE0Nt2rO0BWcDM1vrLbFX7mH0NdZHkcwPs28vx07c18JTZt/Po3MxleiS3MXqV9WtrK1LZ1M1+pH1q/ltpS2fXUNj0RHuPQ4CAfxwmaHBidvWTyAfT28GCdTCYcbBSJ04BHAmua21qprVKIrECT/WVjgVfgak1ffzu1Tc9yVWBmIhzsAgBrVoRz3n3yX3+U9vnbn/+/YHsmwydRd3YhEoKcXYiEIGcXIiHI2YVICHJ2IRKCnF2IhLCQ8k+PAfgEgAvuvr3e9lUAfwbg7bo1X3b3X8y3rY62Vnz4nvcHbRtvvZP2O3/uXLB9zWouXW3ZvInaVq3gFabTzuW8KRIEUYwEi1iKb6+9jQfCtLdzySud49JhlkiY+ZlwiSEAuGs7l/KGtwxTW7nGZUUn95FKjctknuZzlc7yU7Vc4HpejQSGpDL8PmfNfByI9CuW+Xxk0jy3YbUUPq9WRGS++/75B4Ltz7+0n/ZZyJ39rwE8GGj/K3ffUf+Z19GFEMvLvM7u7s8C4PGiQoh/FCzmO/sXzWyfmT1mZjzYWAhxU3C9zv4tAJsA7AAwAuDr7B/NbI+Z7TWzvdMzPLhfCLG0XJezu/uYu1fdvQbg2wB2R/73UXff5e672tv4goMQYmm5Lmc3s2ujKj4F4MCNGY4QYqlYiPT2fQAfAdBvZmcBfAXAR8xsBwAHcBLAny9kZ62tLXj/He8L2m7byaW3/PawjNbWxaOueKYzwI1LK6mIRNLbFs4jFqn+FL2a1khpIiCeSwwRiadYDJd/2nTLOtqnJcclwPwMj+jzVOT0sbDNI/ndas5t1cgxi5U8KuXD81Gt8fecykTOj8gRnRrnEuypE2eo7d77dgbbZ8s8H2IrkQcjSu/8zu7unws0f2e+fkKImws9QSdEQpCzC5EQ5OxCJAQ5uxAJQc4uREJoaMLJVCqFFhLp1d7MSyi1tZJhRpLrxRIbWkx6i0k8HpbKamUuocXkJIskPaxExMOYvOIkYWZ7N48QrFT5vqq1SBZIUuIJABzVYHsqNvgqt1UzXBJ1RA42SXBqtfD4AKAp8p6zVX7M2gq8n4+FJUAAuHh8LNi+ditPOnopFX4aNTa9urMLkRDk7EIkBDm7EAlBzi5EQpCzC5EQ5OxCJISGSm/pdBodXWEJyCPRZrPFsHziRV6Tq0j6AMDM9Ay1lcq8X7EYjjarVLh0VY5EqJUj+5qN1A2bneHRUBUSSdfR20X7dHTxunjdHf3U1pwL13MDgCqr3WeRumzgto4OnoBz/AKfx0I+LFHVajy5koG/r1qVn3OdHVw+Xr9uJbXlZ8Pno0eSc3Z1hCXsdETO1Z1diIQgZxciIcjZhUgIcnYhEoKcXYiE0NDV+ImJSfztE38XtFWzv6X9rlwJBwpMX71E+6QisRGxlfqxsfC+AKBKomt6I+Wkevr7qK0pzad/5nK4JBAAHD5yiNomp8Orz0MbeImndJYrIZ0dfPwbNvC8dmuHwvn6NmxcQ/v0NvEojo5mPsZaJBch0uHglHKVr3SnIyWe0pExrhyOKBedfKW+7OGgnDQXBdDbG37PmUhwmO7sQiQEObsQCUHOLkRCkLMLkRDk7EIkBDm7EAlhIeWfhgB8F8AqzFVVetTdv2lmvQB+CGAYcyWgPuPuV2LbmpyaxlPPPBe0da/dSvt5NSwnvfrcM7TP+rU8f1d/H5eTzp0dpbYKyVvW2ssDSUopHiQzdpaXBLp/9z3UtuOO26httlgItqey/FCfOH2K2g4fOUZt+w+8Sm3dXeEinn/ybz5F+9x72xZqy0VqbK0dHKK2EpHeLJKsLZY3sExy6wFAKhPJa9fNA3laSPBKLc0lYiZERlIoLujOXgHwF+6+DcDdAL5gZrcCeATA0+6+GcDT9b+FEDcp8zq7u4+4+yv111MADgFYA+AhAI/X/+1xAJ9cqkEKIRbPe/rObmbDAHYCeBHASncfAeYuCAD4Y2RCiGVnwc5uZu0AfgzgS+4++R767TGzvWa2t1Tigf9CiKVlQc5uZlnMOfr33P0n9eYxMxus2wcBXAj1dfdH3X2Xu+/K5fjzwUKIpWVeZ7e58infAXDI3b9xjekJAA/XXz8M4Gc3fnhCiBvFQqLe7gXwpwD2m9lr9bYvA/gagB+Z2ecBnAbw6fk21NPbh09/7t8GbU0Dm2m/2amwHHZk/+u0z+AqLsekInm6Wpp5BFWpFi7hs2U7H3vPIF/KmO3nedA+8bE/orbWjhZqmyHSW6RSEyqkrBUAFCrh7QHAhQuXqe3UifPB9tZWPr+jZ8ep7eTBI9SWKvAxHh8NfuDE7o/uon3WD6+mtli0XKo5EqaW5bKcsVxzxvvkLHzMYtLbvM7u7r8DwDZx/3z9hRA3B3qCToiEIGcXIiHI2YVICHJ2IRKCnF2IhNDQhJNmQFMufH05/OYB2m/yalh681h0UolHDE1Hyj9ZRLtobgrHGpVneTmmqxf5GMdO86i3v/v7cGJOALgyFdnf9NVge0cnl7y6esIluQCgLZIo8ezZsLwGAAP94cSSzZ1civztz/l7vnxkH7VVS7zE1tHRcALRs5ESWpu3cSm1q7OV23p4ia2WVh711tUWPq+yzTx5ZGtr+Li48/NXd3YhEoKcXYiEIGcXIiHI2YVICHJ2IRKCnF2IhNBQ6a1WKWNqPCyj/epnP6f9zoyeDbanyuEoNADYty+SXyMir1UqPKoJJNLoqSd/Rbvksly62rHzLmor5TqobbI4S23HT4ejvMbHeX24UoFHvZ0fPUltJ07ybe7a+f5g+7/7wn+gfV564Xlqq1zlEXGTRZ4UJY+w9Hl8L5c9f/vyCLW1ZbjMl81xqSzdxM+DDiK9rV0/TPs89CefDbaXKvz+rTu7EAlBzi5EQpCzC5EQ5OxCJAQ5uxAJoaGr8dlsDoMrB4O2zcMbaD9HeLU4EymtlI6suKfS/BrnNR64kmtuCxuyPMhh9epwQAgAfOSBB6itozUScNHMc9e9cSCcl+/wUV7GadWaYWorRMoupVv4GA8cfjPY/sbhw7RP6/A2ajt/nr/nnm5uG8iF88K1tvM8fpdHeTms8XNHqe3ipXDQDQAUqpGgLZIgcGSCu+cH7w/3qfC0dbqzC5EU5OxCJAQ5uxAJQc4uREKQswuREOTsQiSEeaU3MxsC8F0AqwDUADzq7t80s68C+DMAF+v/+mV3/0VsW5VKBZcvhksG3f3PPkj7ffDDHw62NzXxwINMRF6LlX+qRUohpRHeX7nE9Y58iQetjJ89QW2XCzzg4vIlXnbpOJHYzl8IByABQPsAL3eEJi4rWo5Lb6VKODjlqd/8jvZZv+l2ahvq5RJmc4qfxq0kEKlY4Dnojk8epLb2Dp7Lr+o8iGr0yjS19fcPB9tny/xc/NVvXgq2T03x/IoL0dkrAP7C3V8xsw4AL5vZU3XbX7n7f1vANoQQy8xCar2NABipv54ys0MA+GVWCHFT8p6+s5vZMICdAF6sN33RzPaZ2WNmxh9jEkIsOwt2djNrB/BjAF9y90kA3wKwCcAOzN35v0767TGzvWa2d2qaf08SQiwtC3J2M8tiztG/5+4/AQB3H3P3qrvXAHwbwO5QX3d/1N13ufuujnaefUUIsbTM6+w2VyLlOwAOufs3rmm/NqLlUwB4SRchxLKzkNX4ewH8KYD9ZvZave3LAD5nZjsAOICTAP58vg2lUoY2UrZmfLJA+7267+Vg+8AAXyZYOdBPbeUyl7WuXJmgNhTCY8zU+PbWbOCy1lAP/6Rz7jDPgzYzzXOuDaxcFWxv7eumfdLNXE6azfPjMji4jtpGz4fzBl4aD5enAoDB1ZGyXJFSX9NFPv/IhM+3co3LpU0tJLoRQFMkmrI0fpHakArnmQOAlSTqsFTkJczYdPBZWthq/O8AhN5hVFMXQtxc6Ak6IRKCnF2IhCBnFyIhyNmFSAhydiESQkMTTqYMaMqGI3mKBS55Pffc08F2L3NZqLOVJxQsl3l0UiHPS0plyLVx/fAQ7bP97lupbdM6LstNnAlLVwAweuUSteVawlLTpr6wJAcAFy/yiKzbt26ntttu30ptP/hf3w22ZxBOAAkA5Rl+PEslbvNYlsXm8LGOlWMa3rCR2i6ceYvvK8WjMFva+P62bdsSbC/M8uMyNDgQbP9Njkt8urMLkRDk7EIkBDm7EAlBzi5EQpCzC5EQ5OxCJISGSm+1Wg2zeZKAMZIE8oGPfSK8vRKPkkpH5LValSfy8zSXT9KZsGzU3MYTL45OcClvaoLXPbuc5+O3Zp4E8q3Xjgfbx5/nEVkbN3AJ7QO3bKa2UiQiriUXlpo8EnEYi7BLpfmpSkqlAQDyNVInsMrnd/1aLr0Vpsep7dZOHi330suvUtv5U2E5Lz/Dz2+fvRJsLxV5RKTu7EIkBDm7EAlBzi5EQpCzC5EQ5OxCJAQ5uxAJobFRbylDW3tYvuqKZMrrWBGOCipGZIbmyHUsZzzyylt4tFxTa7hfrcCjk6amJqkt3coTPQ5s4gkiN7XyqLcjJ8K13mBcUsySJKAAcG7kNLX19fOEn8xWynM5qVjkyShnIhFxxUh0WLkYlnozzVwuXbl6BbWdGhmjtrHTZO4BFKb5ezt28LVge18fH4f39IbbI4k5dWcXIiHI2YVICHJ2IRKCnF2IhCBnFyIhzLsab2bNAJ4F0FT////j7l8xs14APwQwjLnyT59x9/DT+XVqtQJmp0jwR41fd7LWHmwfG+MrnEfeOEltzRm+4p7r4qvg/aTc1Or+LtonEwnw6evqo7ZIrA4KeT7NAwPhFf41q8OrtwAwMjpKbYcPH6K24dIGamNKydQUP2azs3yle/IqVzViq/HVUjgQKd3Eg1YOHuClw2IlmQYGVlLbmjt4Lr+BFeF+/St43sBmMv6n/+EZ2mchd/YigH/p7ndirjzzg2Z2N4BHADzt7psBPF3/WwhxkzKvs/scb186s/UfB/AQgMfr7Y8D+OSSjFAIcUNYaH32dL2C6wUAT7n7iwBWuvsIANR/h3PbCiFuChbk7O5edfcdANYC2G1m/AvIuzCzPWa218z2Tk2RxBVCiCXnPa3Gu/sEgF8DeBDAmJkNAkD99wXS51F33+Xuuzo6+COKQoilZV5nN7MVZtZdf90C4I8AvAngCQAP1//tYQA/W6pBCiEWz0ICYQYBPG5macxdHH7k7k+a2fMAfmRmnwdwGsCn591SzVEjZXxSketOphwO4ugkpaQA4OUXfkNto2M8kMSyPChk9+73B9vvu2cX7XP1Kpea9r3yIrXNFHjgx+HTZ6jt+MmTwfb8LP8K5c6TuDV38mCMyckpapsiJapmJrlsGEklh0yaW7sinxhXbwjLgz19g7TPwGouea3eeTu19UZy0OViuQ2ZLRK8BA/7SypSgmpeZ3f3fQB2BtrHAdw/X38hxM2BnqATIiHI2YVICHJ2IRKCnF2IhCBnFyIhWCxn1Q3fmdlFAKfqf/YD4BpY49A43onG8U7+sY1jvbsH9dKGOvs7dmy21925QK1xaBwaxw0dhz7GC5EQ5OxCJITldPZHl3Hf16JxvBON4538kxnHsn1nF0I0Fn2MFyIhLIuzm9mDZvaWmR01s2XLXWdmJ81sv5m9ZmZ7G7jfx8zsgpkduKat18yeMrMj9d+8ttLSjuOrZnauPievmdnHGzCOITN7xswOmdlBM/v39faGzklkHA2dEzNrNrOXzOz1+jj+c719cfPh7g39AZAGcAzARgA5AK8DuLXR46iP5SSA/mXY74cA3AXgwDVt/xXAI/XXjwD4L8s0jq8C+I8Nno9BAHfVX3cAOAzg1kbPSWQcDZ0TzEX7ttdfZwG8CODuxc7HctzZdwM46u7H3b0E4AeYS16ZGNz9WQCX39Xc8ASeZBwNx91H3P2V+uspAIcArEGD5yQyjobic9zwJK/L4exrAFybfeEslmFC6ziAX5rZy2a2Z5nG8DY3UwLPL5rZvvrH/CX/OnEtZjaMufwJy5rU9F3jABo8J0uR5HU5nD2UcmS5JIF73f0uAB8D8AUz+9AyjeNm4lsANmGuRsAIgK83asdm1g7gxwC+5O68KkTjx9HwOfFFJHllLIeznwUwdM3fawGcX4ZxwN3P139fAPBTzH3FWC4WlMBzqXH3sfqJVgPwbTRoTswsizkH+567/6Te3PA5CY1jueakvu/3nOSVsRzO/nsAm81sg5nlAHwWc8krG4qZtZlZx9uvAXwUwIF4ryXlpkjg+fbJVOdTaMCcmJkB+A6AQ+7+jWtMDZ0TNo5Gz8mSJXlt1Arju1YbP465lc5jAP5ymcawEXNKwOsADjZyHAC+j7mPg2XMfdL5PIA+zJXROlL/3btM4/gbAPsB7KufXIMNGMd9mPsqtw/Aa/Wfjzd6TiLjaOicALgDwKv1/R0A8J/q7YuaDz1BJ0RC0BN0QiQEObsQCUHOLkRCkLMLkRDk7EIkBDm7EAlBzi5EQpCzC5EQ/j8Td47fuM9PmAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label is: [9]\n"
     ]
    }
   ],
   "source": [
    "print('The label is:', y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really want is the probability of each of the 10 different classes. For that, we need 10 output neurons in our neural network. Since we have 10 output neurons, our labels must match this as well. To do this, we convert the label into a set of 10 numbers where each number represents if the image belongs to that class or not. So if an image belongs to the first class, the first number of this set will be a 1 and all other numbers in this set will be a 0. To convert our labels to our one-hot encoding, we use a function in Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "y_train_one_hot = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one hot label is: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('The one hot label is:', y_train_one_hot[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common step we do is to let the values to be between 0 and 1, which will aid in the training of out neural network. Since our pixel values already take the values between 0 and 255, we simply need to divide by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23137255, 0.24313726, 0.24705882],\n",
       "        [0.16862746, 0.18039216, 0.1764706 ],\n",
       "        [0.19607843, 0.1882353 , 0.16862746],\n",
       "        ...,\n",
       "        [0.61960787, 0.5176471 , 0.42352942],\n",
       "        [0.59607846, 0.49019608, 0.4       ],\n",
       "        [0.5803922 , 0.4862745 , 0.40392157]],\n",
       "\n",
       "       [[0.0627451 , 0.07843138, 0.07843138],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.07058824, 0.03137255, 0.        ],\n",
       "        ...,\n",
       "        [0.48235294, 0.34509805, 0.21568628],\n",
       "        [0.46666667, 0.3254902 , 0.19607843],\n",
       "        [0.47843137, 0.34117648, 0.22352941]],\n",
       "\n",
       "       [[0.09803922, 0.09411765, 0.08235294],\n",
       "        [0.0627451 , 0.02745098, 0.        ],\n",
       "        [0.19215687, 0.10588235, 0.03137255],\n",
       "        ...,\n",
       "        [0.4627451 , 0.32941177, 0.19607843],\n",
       "        [0.47058824, 0.32941177, 0.19607843],\n",
       "        [0.42745098, 0.28627452, 0.16470589]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.8156863 , 0.6666667 , 0.3764706 ],\n",
       "        [0.7882353 , 0.6       , 0.13333334],\n",
       "        [0.7764706 , 0.6313726 , 0.10196079],\n",
       "        ...,\n",
       "        [0.627451  , 0.52156866, 0.27450982],\n",
       "        [0.21960784, 0.12156863, 0.02745098],\n",
       "        [0.20784314, 0.13333334, 0.07843138]],\n",
       "\n",
       "       [[0.7058824 , 0.54509807, 0.3764706 ],\n",
       "        [0.6784314 , 0.48235294, 0.16470589],\n",
       "        [0.7294118 , 0.5647059 , 0.11764706],\n",
       "        ...,\n",
       "        [0.72156864, 0.5803922 , 0.36862746],\n",
       "        [0.38039216, 0.24313726, 0.13333334],\n",
       "        [0.3254902 , 0.20784314, 0.13333334]],\n",
       "\n",
       "       [[0.69411767, 0.5647059 , 0.45490196],\n",
       "        [0.65882355, 0.5058824 , 0.36862746],\n",
       "        [0.7019608 , 0.5568628 , 0.34117648],\n",
       "        ...,\n",
       "        [0.84705883, 0.72156864, 0.54901963],\n",
       "        [0.5921569 , 0.4627451 , 0.32941177],\n",
       "        [0.48235294, 0.36078432, 0.28235295]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Training our Convolutional Neural Network\n",
    "\n",
    "We need to define the architecture (template) first before fitting the best numbers into this architecture by learning from the data. In summary, the architecture we will build in this post is this:\n",
    "* Conv Layer (Filter size 3x3, Depth 32)\n",
    "* Conv Layer (Filter size 3x3, Depth 32)\n",
    "* Max Pool Layer (Filter size 2x2)\n",
    "* Dropout Layer (Prob of dropout 0.25)\n",
    "* Conv Layer (Filter size 3x3, Depth 64)\n",
    "* Conv Layer (Filter size 3x3, Depth 64)\n",
    "* Max Pool Layer (Filter size 2x2)\n",
    "* Dropout Layer (Prob of dropout 0.25)\n",
    "* FC Layer (512 neurons)\n",
    "* Dropout Layer (Prob of dropout 0.5)\n",
    "* FC Layer, Softmax (10 neurons)\n",
    "\n",
    "We will be using Keras to build our architecture. Let's import the code from Keras that we will need to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then call an empty Sequential model and 'add' to this model layer by layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer is a conv layer with filter size 3x3, stride size 1 (in both dimensions), and depth 32. The padding is the 'same' and the activation is 'relu' (these two settings will apply to all layers in our CNN). We add this layer to our empty sequential model using the function model.add().\n",
    "\n",
    "The first number 32 refers to the depth. The next pair of number (3,3) refer to the filter width and size. Then, we specify activation which is 'relu' and padding which is 'same'. Notice that we did not specify stride. This is because stride=1 is a default setting, and unless we want to change this setting, we need not specify it.\n",
    "\n",
    "If you recall, we also need to specify an input size for our first layer; subsequent layers does not have this specification since they can infer the input size from the output size of the previous layer.\n",
    "\n",
    "All that being said, our first layer in code looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second layer looks like this in code (we don't need to specify the input size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next layer is a max pooling layer with pool size 2 x 2 and stride 2 (in both dimensions). The default for a max pooling layer stride is the pool size, so we don't have to specify the stride:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we add a dropout layer with probability 0.25 of dropout so as to prevent overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it, our first four layers in code. The next four layers look really similar (except the depth of the conv layer is 64 instead of 32):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we have to code in our fully connected layer. However, at this point, our neurons are spatially arranged in a cube-like format rather than in just one row. To make this cube-like format of neurons into one row, we have to first flatten it. We do so by adding a Flatten layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a dense (FC) layer of 512 neurons with relu activation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(512, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add another dropout of probability 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, we have a dense (FC) layer with 10 neurons and softmax activation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done with specifying out architecture! To see a summary of the full architecture, we run the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fill in the best numbers after we've specified our architecture. We'll compile the model with our settings below.\n",
    "\n",
    "The loss function we use is called categorical cross entropy, which is applicable for a classification problem of many classes. The optimizer we use here is Adam. We haven't gone through the intuition of Adam yet, but know that Adam is simply a type of stochastic gradient descent (with a few modifications) so that it trains better. Lastly, we want to track the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, it's time to run our training.\n",
    "\n",
    "We train our model with batch size 32 and 20 epochs. We use the setting validation_split=0.2 instead of validation_data. With this shortcut, we did not need to split our dataset into a train and validation set at the start! Instead, we simply specify how much of our dataset will be used as a validation set. In this case, 20% of our dataset is used as a validation set. This will take a shile on a CPU, so you might want to start training and get some coffee before coming back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 86s 2ms/step - loss: 1.6049 - accuracy: 0.4083 - val_loss: 1.2460 - val_accuracy: 0.5528\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 85s 2ms/step - loss: 1.2272 - accuracy: 0.5608 - val_loss: 1.0281 - val_accuracy: 0.6364\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 85s 2ms/step - loss: 1.0673 - accuracy: 0.6184 - val_loss: 1.0102 - val_accuracy: 0.6403\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 85s 2ms/step - loss: 0.9614 - accuracy: 0.6609 - val_loss: 0.8609 - val_accuracy: 0.7016\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 86s 2ms/step - loss: 0.8852 - accuracy: 0.6874 - val_loss: 0.8033 - val_accuracy: 0.7205\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 86s 2ms/step - loss: 0.8332 - accuracy: 0.7031 - val_loss: 0.7829 - val_accuracy: 0.7279\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 86s 2ms/step - loss: 0.7937 - accuracy: 0.7206 - val_loss: 0.7913 - val_accuracy: 0.7288\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 0.7441 - accuracy: 0.7377 - val_loss: 0.7327 - val_accuracy: 0.7501\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 85s 2ms/step - loss: 0.7059 - accuracy: 0.7534 - val_loss: 0.7384 - val_accuracy: 0.7471\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 85s 2ms/step - loss: 0.6773 - accuracy: 0.7612 - val_loss: 0.7194 - val_accuracy: 0.7580\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 0.6463 - accuracy: 0.7706 - val_loss: 0.6836 - val_accuracy: 0.7690\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.6255 - accuracy: 0.7791 - val_loss: 0.7613 - val_accuracy: 0.7475\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.5989 - accuracy: 0.7890 - val_loss: 0.7109 - val_accuracy: 0.7622\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.5787 - accuracy: 0.7939 - val_loss: 0.6851 - val_accuracy: 0.7667\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.5588 - accuracy: 0.8026 - val_loss: 0.6991 - val_accuracy: 0.7648\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.5377 - accuracy: 0.8123 - val_loss: 0.7019 - val_accuracy: 0.7699\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.5219 - accuracy: 0.8156 - val_loss: 0.7070 - val_accuracy: 0.7615\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.5060 - accuracy: 0.8216 - val_loss: 0.6933 - val_accuracy: 0.7740\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 93s 2ms/step - loss: 0.4923 - accuracy: 0.8259 - val_loss: 0.6823 - val_accuracy: 0.7805\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 93s 2ms/step - loss: 0.4820 - accuracy: 0.8301 - val_loss: 0.7230 - val_accuracy: 0.7681\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train_one_hot, batch_size=32, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you've done training, we can visualize the model training and validation loss as well as training / validation accuracy over the number of epochs using the below code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are done with tweaking our hyperparameters, we can run it on our test dataset below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test_one_hot)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_cifar10_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out with your own images\n",
    "\n",
    "Now that we have a model, let's try it on our own images. To do so, place your image in the same directory as your notebook. For the purpose of this post, I'm going to use an image of a cat (which you can download here (link)). Now, we read in our JPEG file as an array of pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = plt.imread('cat.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first thing we have to do is to resize the image of our cat so that we can fit it into our model (input size of 32 32 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "my_image_resized = resize(my_image, (32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imshow(my_image_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we see what our trained model will output when given an image of out cat, using this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "probabilities = model.predict(np.array([my_image_resized,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_to_class = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "index = np.argsort(probabilities[0, :])\n",
    "print('Most likely class: ', {number_to_class[index[9]]}, '-- Probability:', probabilities[0, index[9]])\n",
    "print('Second most likely class: ', {number_to_class[index[8]]}, '-- Probability:', probabilities[0, index[8]])\n",
    "print('Third most likely class: ', {number_to_class[index[7]]}, '-- Probability:', probabilities[0, index[7]])\n",
    "print('Fourth most likely class: ', {number_to_class[index[6]]}, '-- Probability:', probabilities[0, index[6]])\n",
    "print('Fifth most likely class: ', {number_to_class[index[5]]}, '-- Probability:', probabilities[0, index[5]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}